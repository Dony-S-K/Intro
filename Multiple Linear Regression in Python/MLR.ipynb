{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading the Dataset\n",
    "2. Descrptive statistics of Data \n",
    "3. Data Cleaning\n",
    "4. Data splitting into independendent and Dependent variables\n",
    "5. Label encoding \n",
    "6. One hot encoding\n",
    "7. Train-Test Split\n",
    "8. Model Building\n",
    "9. Model Summary\n",
    "10. Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Loading Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True) #prevent numpy exponential\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3  144372.41       118671.85        383199.62    New York  182901.99\n",
      "4  142107.34             NaN        366168.42     Florida  166187.94\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"MLR_DATA.csv\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Descrptive statistics of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 5)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 5 columns):\n",
      "R&D Spend          50 non-null float64\n",
      "Administration     48 non-null float64\n",
      "Marketing Spend    50 non-null float64\n",
      "State              50 non-null object\n",
      "Profit             50 non-null float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 2.0+ KB\n",
      "None\n",
      "           R&D Spend  Administration  Marketing Spend         Profit\n",
      "count      50.000000       48.000000        50.000000      50.000000\n",
      "mean    73721.615600   123428.272292    211025.097800  112012.639200\n",
      "std     45902.256482    26276.227003    122290.310726   40306.180338\n",
      "min         0.000000    51743.150000         0.000000   14681.400000\n",
      "25%     39936.370000   107947.135000    129300.132500   90138.902500\n",
      "50%     73051.080000   123467.895000    212716.240000  107978.190000\n",
      "75%    101602.800000   145190.700000    299469.085000  139765.977500\n",
      "max    165349.200000   182645.560000    471784.100000  192261.830000\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.info())\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R&D Spend          False\n",
      "Administration      True\n",
      "Marketing Spend    False\n",
      "State              False\n",
      "Profit             False\n",
      "dtype: bool\n",
      "R&D Spend          0\n",
      "Administration     2\n",
      "Marketing Spend    0\n",
      "State              0\n",
      "Profit             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().any())\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling with mean value\n",
    "data.Administration = data.Administration.fillna(data.Administration.mean())\n",
    "#print(data.isnull().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Split the data into X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into X & Y\n",
    "X = data.iloc[:, :-1].values\n",
    "Y = data.iloc[:, 4].values\n",
    "#.iloc is used whenever index based position locating is carried out in pandas\n",
    "#.values to convert dataframe to numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Categorical into Numerals\n",
    "LE = LabelEncoder()\n",
    "X[:,3] = LE.fit_transform(X[:, 3])\n",
    "#X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.iloc[1,:]\n",
    "#X.iloc[1,:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.        ,      0.        ,      1.        ,\n",
       "        165349.2       , 136897.8       , 471784.1       ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "        162597.7       , 151377.59      , 443898.53      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "        153441.51      , 101145.55      , 407934.54      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "        144372.41      , 118671.85      , 383199.62      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "        142107.34      , 123428.27229167, 366168.42      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "        131876.9       ,  99814.71      , 362861.36      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "        134615.46      , 147198.87      , 127716.82      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "        130298.13      , 145530.06      , 323876.68      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "        120542.52      , 148718.95      , 311613.29      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "        123334.88      , 108679.17      , 304981.62      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "        101913.08      , 110594.11      , 229160.95      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "        100671.96      ,  91790.61      , 249744.55      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         93863.75      , 127320.38      , 249839.44      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         91992.39      , 135495.07      , 252664.93      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "        119943.24      , 156547.42      , 256512.92      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "        114523.61      , 122616.84      , 261776.23      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         78013.11      , 121597.55      , 264346.06      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         94657.16      , 145077.58      , 282574.31      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         91749.16      , 114175.79      , 294919.57      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         86419.7       , 153514.11      ,      0.        ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         76253.86      , 113867.3       , 298664.47      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         78389.47      , 153773.43      , 299737.29      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         73994.56      , 122782.75      , 303319.26      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         67532.53      , 105751.03      , 304768.73      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         77044.01      ,  99281.34      , 140574.81      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         64664.71      , 139553.16      , 137962.62      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         75328.87      , 144135.98      , 134050.07      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         72107.6       , 127864.55      , 353183.81      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         66051.52      , 182645.56      , 118148.2       ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         65605.48      , 153032.06      , 107138.38      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         61994.48      , 115641.28      ,  91131.24      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         61136.38      , 152701.92      ,  88218.23      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         63408.86      , 129219.61      ,  46085.25      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         55493.95      , 103057.49      , 214634.81      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         46426.07      , 157693.92      , 210797.67      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         46014.02      ,  85047.44      , 205517.64      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         28663.76      , 127056.21      , 201126.82      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         44069.95      , 123428.27229167, 197029.42      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         20229.59      ,  65947.93      , 185265.1       ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         38558.51      ,  82982.09      , 174999.3       ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         28754.33      , 118546.05      , 172795.67      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "         27892.92      ,  84710.77      , 164470.71      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         23640.93      ,  96189.63      , 148001.11      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "         15505.73      , 127382.3       ,  35534.17      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "         22177.74      , 154806.14      ,  28334.72      ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "          1000.23      , 124153.04      ,   1903.93      ],\n",
       "       [     0.        ,      1.        ,      0.        ,\n",
       "          1315.46      , 115816.21      , 297114.46      ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "             0.        , 135426.92      ,      0.        ],\n",
       "       [     0.        ,      0.        ,      1.        ,\n",
       "           542.05      ,  51743.15      ,      0.        ],\n",
       "       [     1.        ,      0.        ,      0.        ,\n",
       "             0.        , 116983.8       ,  45173.06      ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Onehot Encoding\n",
    "OHE = OneHotEncoder(categorical_features = [3])\n",
    "X = OHE.fit_transform(X).toarray()\n",
    "#print(data.head())\n",
    "X      #3 dummy variables are created for state variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.        ,      1.        , 165349.2       ,\n",
       "        136897.8       , 471784.1       ],\n",
       "       [     0.        ,      0.        , 162597.7       ,\n",
       "        151377.59      , 443898.53      ],\n",
       "       [     1.        ,      0.        , 153441.51      ,\n",
       "        101145.55      , 407934.54      ],\n",
       "       [     0.        ,      1.        , 144372.41      ,\n",
       "        118671.85      , 383199.62      ],\n",
       "       [     1.        ,      0.        , 142107.34      ,\n",
       "        123428.27229167, 366168.42      ],\n",
       "       [     0.        ,      1.        , 131876.9       ,\n",
       "         99814.71      , 362861.36      ],\n",
       "       [     0.        ,      0.        , 134615.46      ,\n",
       "        147198.87      , 127716.82      ],\n",
       "       [     1.        ,      0.        , 130298.13      ,\n",
       "        145530.06      , 323876.68      ],\n",
       "       [     0.        ,      1.        , 120542.52      ,\n",
       "        148718.95      , 311613.29      ],\n",
       "       [     0.        ,      0.        , 123334.88      ,\n",
       "        108679.17      , 304981.62      ],\n",
       "       [     1.        ,      0.        , 101913.08      ,\n",
       "        110594.11      , 229160.95      ],\n",
       "       [     0.        ,      0.        , 100671.96      ,\n",
       "         91790.61      , 249744.55      ],\n",
       "       [     1.        ,      0.        ,  93863.75      ,\n",
       "        127320.38      , 249839.44      ],\n",
       "       [     0.        ,      0.        ,  91992.39      ,\n",
       "        135495.07      , 252664.93      ],\n",
       "       [     1.        ,      0.        , 119943.24      ,\n",
       "        156547.42      , 256512.92      ],\n",
       "       [     0.        ,      1.        , 114523.61      ,\n",
       "        122616.84      , 261776.23      ],\n",
       "       [     0.        ,      0.        ,  78013.11      ,\n",
       "        121597.55      , 264346.06      ],\n",
       "       [     0.        ,      1.        ,  94657.16      ,\n",
       "        145077.58      , 282574.31      ],\n",
       "       [     1.        ,      0.        ,  91749.16      ,\n",
       "        114175.79      , 294919.57      ],\n",
       "       [     0.        ,      1.        ,  86419.7       ,\n",
       "        153514.11      ,      0.        ],\n",
       "       [     0.        ,      0.        ,  76253.86      ,\n",
       "        113867.3       , 298664.47      ],\n",
       "       [     0.        ,      1.        ,  78389.47      ,\n",
       "        153773.43      , 299737.29      ],\n",
       "       [     1.        ,      0.        ,  73994.56      ,\n",
       "        122782.75      , 303319.26      ],\n",
       "       [     1.        ,      0.        ,  67532.53      ,\n",
       "        105751.03      , 304768.73      ],\n",
       "       [     0.        ,      1.        ,  77044.01      ,\n",
       "         99281.34      , 140574.81      ],\n",
       "       [     0.        ,      0.        ,  64664.71      ,\n",
       "        139553.16      , 137962.62      ],\n",
       "       [     1.        ,      0.        ,  75328.87      ,\n",
       "        144135.98      , 134050.07      ],\n",
       "       [     0.        ,      1.        ,  72107.6       ,\n",
       "        127864.55      , 353183.81      ],\n",
       "       [     1.        ,      0.        ,  66051.52      ,\n",
       "        182645.56      , 118148.2       ],\n",
       "       [     0.        ,      1.        ,  65605.48      ,\n",
       "        153032.06      , 107138.38      ],\n",
       "       [     1.        ,      0.        ,  61994.48      ,\n",
       "        115641.28      ,  91131.24      ],\n",
       "       [     0.        ,      1.        ,  61136.38      ,\n",
       "        152701.92      ,  88218.23      ],\n",
       "       [     0.        ,      0.        ,  63408.86      ,\n",
       "        129219.61      ,  46085.25      ],\n",
       "       [     1.        ,      0.        ,  55493.95      ,\n",
       "        103057.49      , 214634.81      ],\n",
       "       [     0.        ,      0.        ,  46426.07      ,\n",
       "        157693.92      , 210797.67      ],\n",
       "       [     0.        ,      1.        ,  46014.02      ,\n",
       "         85047.44      , 205517.64      ],\n",
       "       [     1.        ,      0.        ,  28663.76      ,\n",
       "        127056.21      , 201126.82      ],\n",
       "       [     0.        ,      0.        ,  44069.95      ,\n",
       "        123428.27229167, 197029.42      ],\n",
       "       [     0.        ,      1.        ,  20229.59      ,\n",
       "         65947.93      , 185265.1       ],\n",
       "       [     0.        ,      0.        ,  38558.51      ,\n",
       "         82982.09      , 174999.3       ],\n",
       "       [     0.        ,      0.        ,  28754.33      ,\n",
       "        118546.05      , 172795.67      ],\n",
       "       [     1.        ,      0.        ,  27892.92      ,\n",
       "         84710.77      , 164470.71      ],\n",
       "       [     0.        ,      0.        ,  23640.93      ,\n",
       "         96189.63      , 148001.11      ],\n",
       "       [     0.        ,      1.        ,  15505.73      ,\n",
       "        127382.3       ,  35534.17      ],\n",
       "       [     0.        ,      0.        ,  22177.74      ,\n",
       "        154806.14      ,  28334.72      ],\n",
       "       [     0.        ,      1.        ,   1000.23      ,\n",
       "        124153.04      ,   1903.93      ],\n",
       "       [     1.        ,      0.        ,   1315.46      ,\n",
       "        115816.21      , 297114.46      ],\n",
       "       [     0.        ,      0.        ,      0.        ,\n",
       "        135426.92      ,      0.        ],\n",
       "       [     0.        ,      1.        ,    542.05      ,\n",
       "         51743.15      ,      0.        ],\n",
       "       [     0.        ,      0.        ,      0.        ,\n",
       "        116983.8       ,  45173.06      ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Avoiding Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "#X_train\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "mlr_reg = LR.fit(X_train, Y_train)\n",
    "mlr_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients of the MLR Model:\n",
      " [-783.02407331  982.96059598    0.76935778    0.05071577    0.03732572]\n",
      "\n",
      " Intercept of the MLR Model:\n",
      " 40268.98329768915\n",
      "\n",
      " R_square value of the MLR Model:\n",
      " 0.9505092969949016\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients of the MLR Model:\\n\", mlr_reg.coef_)\n",
    "print(\"\\n Intercept of the MLR Model:\\n\", mlr_reg.intercept_)\n",
    "print(\"\\n R_square value of the MLR Model:\\n\", mlr_reg.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Model Testing/Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of Training set:  9002.198976631764\n",
      " - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "RMSE of Test set:  9609.172808064694\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred = mlr_reg.predict(X_train)\n",
    "MSE_Train = mean_squared_error(Y_train, Y_train_pred)\n",
    "print(\"RMSE of Training set: \", np.sqrt(MSE_Train))\n",
    "#print(MSE_Train)\n",
    "print(\" -\"*25)\n",
    "\n",
    "Y_test_pred = mlr_reg.predict(X_test)\n",
    "MSE_Test = mean_squared_error(Y_test, Y_test_pred)\n",
    "print(\"RMSE of Test set: \", np.sqrt(MSE_Test))\n",
    "#print(MSE_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103282.38 144259.4  146121.95  77798.83 191050.39 105008.31  81229.06\n",
      "  97483.56 110352.25 166187.94]\n",
      "[103976.18633735 131698.86509089 132056.04262578  71380.75341604\n",
      " 177893.50291811 116396.07531112  67075.48923205  99324.89747839\n",
      " 113962.8804579  168744.6059647 ]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n",
    "print(Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?train_test_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
